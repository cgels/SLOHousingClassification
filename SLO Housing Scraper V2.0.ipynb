{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load house_scaper.py\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import sqlite3\n",
    "import datetime\n",
    "\n",
    "df = pd.DataFrame({\"MLS\": [],\"Street\": [], \"City\":[],\"ListPrice\":[],\"Bedrooms\":[],\"Bathrooms\":[],\"SqFt\":[],\"Date\":[],  \"Price/SqFt\":[]})\n",
    "months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\",\n",
    "              \"November\", \"December\"]\n",
    "month_map = {key: int(val) for key, val in zip(months, range(1, 13))}\n",
    "\n",
    "\n",
    "def sqlize_string(string):\n",
    "    return \"'\" + string + \"'\"\n",
    "\n",
    "def get_date(string):\n",
    "    chunked = string.split()\n",
    "    return sqlize_string(str(datetime.date(2016, month_map[chunked[0]], int(chunked[1]))))\n",
    "\n",
    "def scraping(dataframe):\n",
    "    page = requests.get(\"http://www.slocountyhomes.com/newlistex.php\")\n",
    "    data = BeautifulSoup(page.text, \"html.parser\")\n",
    "    hdrs = [\"Bathrooms\", \"Bedrooms\", \"City\", \"Date\", \"List Price\", \"MLS\", \"Price/SqFt\", \"SqFt\", \"Street\"]\n",
    "    idx_map = { hdr:idx for hdr, idx in zip(hdrs, range(len(hdrs))) }\n",
    "\n",
    "\n",
    "    table_rows = data.find_all('tr')\n",
    "    # print(table_rows)\n",
    "    listing_date = \"\"\n",
    "    for row in table_rows:\n",
    "        row_entry = [0] * len(hdrs)\n",
    "        cells = row.find_all(\"td\", recursive=True)\n",
    "        if len(cells) == 1:\n",
    "            listing_date = cells[0].text.strip()\n",
    "            assert listing_date != \"\"\n",
    "\n",
    "        elif 0 < len(cells) <= 8 and len(cells) != 3:\n",
    "            ## CELL ORDER -->   MLS #\tStreet\tCity\tList Price\tBeds\tBaths\tSq Footage\n",
    "            row_entry[idx_map[\"MLS\"]] = int(cells[0].text.strip())\n",
    "            row_entry[idx_map[\"Street\"]] = sqlize_string(cells[1].text.strip())\n",
    "            row_entry[idx_map[\"City\"]] = sqlize_string(cells[2].text.strip())\n",
    "            row_entry[idx_map[\"List Price\"]] = int(cells[3].text.strip()[1:].replace(\",\", \"\"))\n",
    "            row_entry[idx_map[\"Bedrooms\"]] = int(cells[4].text.strip())\n",
    "            row_entry[idx_map[\"Bathrooms\"]] = int(cells[5].text.strip())\n",
    "            try: # handle missing Sq footage\n",
    "                row_entry[idx_map[\"SqFt\"]] = int(cells[6].text.strip())\n",
    "                row_entry[idx_map[\"Price/SqFt\"]] = row_entry[idx_map[\"List Price\"]] / row_entry[\n",
    "                    idx_map[\"SqFt\"]]\n",
    "            except ValueError:\n",
    "                row_entry[idx_map[\"SqFt\"]] = -1\n",
    "            row_entry[idx_map[\"Date\"]] = get_date(listing_date)\n",
    "            ## append this row to dataframe\n",
    "            # print(row_entry)\n",
    "            dataframe.loc[len(dataframe)] = row_entry\n",
    "    ## data integrity\n",
    "    dataframe.drop(dataframe[dataframe.SqFt == -1].index, inplace=True)\n",
    "    dataframe.drop_duplicates(inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "df = scraping(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
